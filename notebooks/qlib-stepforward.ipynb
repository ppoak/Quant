{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qlib Step Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10922:MainThread](2022-08-24 09:04:10,502) INFO - qlib.Initialization - [config.py:413] - default_conf: client.\n",
      "[10922:MainThread](2022-08-24 09:04:11,925) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[10922:MainThread](2022-08-24 09:04:11,926) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/ppoak/Quant/data/qlib-day')}\n"
     ]
    }
   ],
   "source": [
    "import qlib\n",
    "qlib.init(provider_uri=\"../data/qlib-day/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Process vs Infer Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learn process need to learn some parameters from given last time period, which is set in the parameters as `fit_start_time` and `fit_end_time`. For example, the zscore mean and standard deviation can be calculated from the last period. Then, the parameters will directly be used in the new coming dataset.\n",
    "\n",
    "Every processor implemented a `__call__` function, this is the entrypoint for the processor's actual call. What is different is that processors used with learning have the `fit` method, which summarize the information / experience from the past time period.\n",
    "\n",
    "Here we implement a processor which can perform MAD deextreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from qlib.data.dataset.processor import Processor, get_group_columns\n",
    "\n",
    "class CSMADDeextreme(Processor):\n",
    "    def __init__(self, fields_group: str = None, n: int = 5):\n",
    "        self.fields_group = fields_group\n",
    "        self.n = n\n",
    "    \n",
    "    def __call__(self, df: pd.DataFrame):\n",
    "        cols = get_group_columns(df, self.fields_group)\n",
    "        csmed = df[cols].groupby(\"datetime\").median()\n",
    "        csmad = df[cols].groupby(\"datetime\").apply(\n",
    "            lambda x: x - csmed).abs().groupby(\"datetime\").median()\n",
    "        return df[cols].clip(csmed - self.n * csmad, csmed + self.n * csmad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[8633:MainThread](2022-08-23 15:56:31,828) INFO - qlib.timer - [log.py:117] - Time cost: 0.572s | Loading data Done\n",
      "[8633:MainThread](2022-08-23 15:56:32,129) INFO - qlib.timer - [log.py:117] - Time cost: 0.298s | CSMADDeextreme Done\n",
      "[8633:MainThread](2022-08-23 15:56:32,132) INFO - qlib.timer - [log.py:117] - Time cost: 0.302s | fit & process data Done\n",
      "[8633:MainThread](2022-08-23 15:56:32,134) INFO - qlib.timer - [log.py:117] - Time cost: 0.879s | Init data Done\n"
     ]
    }
   ],
   "source": [
    "from qlib.utils import init_instance_by_config\n",
    "\n",
    "config = {\n",
    "    \"class\": \"DataHandlerLP\",\n",
    "    \"module_path\": \"qlib.data.dataset.handler\",\n",
    "    \"kwargs\": {\n",
    "        \"instruments\": \"000016.XSHG\",\n",
    "        \"start_time\": \"20200101\", \n",
    "        \"end_time\": \"20210101\",\n",
    "        \"data_loader\": {\n",
    "            \"class\": \"QlibDataLoader\",\n",
    "            \"module_path\": \"qlib.data.dataset.loader\",\n",
    "            \"kwargs\": {\n",
    "                \"config\": [(\"$close / Ref($close, 60) - 1\",), (\"MOM60\",)],\n",
    "            },\n",
    "        },\n",
    "        \"infer_processors\": [CSMADDeextreme(n=7)],\n",
    "    }\n",
    "}\n",
    "\n",
    "h = init_instance_by_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime    instrument \n",
       "2020-01-02  600000.XSHG    0.040033\n",
       "            600009.XSHG   -0.009855\n",
       "            600010.XSHG   -0.101351\n",
       "            600016.XSHG    0.035831\n",
       "            600028.XSHG    0.031936\n",
       "                             ...   \n",
       "2020-12-31  603160.XSHG   -0.011062\n",
       "            603259.XSHG    0.327291\n",
       "            603288.XSHG    0.237137\n",
       "            603501.XSHG    0.302926\n",
       "            603986.XSHG    0.140893\n",
       "Name: MOM60, Length: 13608, dtype: float32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.fetch(data_key=\"infer\", squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oprations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qlib provide us a series of data operators. There are five main operators base classes:\n",
    "\n",
    "1. NpElemOperator\n",
    "2. NpPairOperator\n",
    "3. Rolling\n",
    "4. PairRolling\n",
    "5. TResample\n",
    "\n",
    "*The above base classes is the second level base class under the user interface, it doesn't include all base classes in `qlib.data.ops`*\n",
    "\n",
    "First, the `NPElemOperator` controls the element-wised feature without any time-related parameter, like calculating the sign of the feature with `Sign`, calculating the absolute value of the feature with `Abs` and so on.\n",
    "\n",
    "Second, the `NpPairOperator` is mainly used for the interactions with two features, like calculating the added feature of two different feature with `Add`, comparing whether one feature is not less than the other with `Ge` and so on. In the `_load_internal` part for `NpPairOperator` and `NpElemOperator`, where the real calculating part locates, indicate that the principle of this operator is `getattr(np, func)`.\n",
    "\n",
    "What is worth mentioning is that one `Ternary Conditional Operator` frequently use in coding language is also implemented. We can judge the condition and apply values due to different results by `If`. The loading data part is in the `_load_internal` method, which implies the realization of this operator is `np.where`.\n",
    "\n",
    "Third, the `Rolling` operator takes a period as input, and classes based on it will apply functions in the rolling window. We can easily compute mean, skew or other basic statistic indicators on it by `Mean`, `Skew` or other functions. But the operator `Slope`, `Rsquare`, `Resi` use the cython as backend, which is used for calculating the slope, r square and residual in linear regression for data in the rolling window.\n",
    "\n",
    "Fourth, the `PairRolling` part is something like *multi-column rolling* in pandas rolling procession. We can compute rolling window correlation and rolling window covariance by `Corr` and `Cov` based on it. In the `Rolling` and `PairRolling` operators, most functions are realized by pandas. Qlib takes the expression as input, constructing a rolling window, and get the function attributions of the rolling window and finally apply on it.\n",
    "\n",
    "Fifth, the `TResample` is a operator used for resample. The internal calls the pandas resample class interfaces. At present it only it is not implemented for more usage.\n",
    "\n",
    "The real data fetching interface of a `Expression` class is `_load_internal` method, and this is the underlaying the `load` method in `Dataloader` class. When the `load` method of a `Dataloader` class is called, the data loading jobs will be distributed to the workers, the number of the workers depends on `max(len(instruments), system_cores)`. Once jobs are distributed, `joblib` module will run the tasks parallely and computing the expression, finally return data. So **cython and parallel working is the key to the fast factor constructing (mostly because of parallel working because cython part takes so little)**\n",
    "\n",
    "In the next cell we implemented one dummy operator as a self-defined operator example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qlib.data.ops import NpElemOperator, Operators\n",
    "\n",
    "class AbsPlusLog(NpElemOperator):\n",
    "    \"\"\"Calculating standard deviation in the resampled data window\"\"\"\n",
    "    def __init__(self, feature):\n",
    "        super().__init__(feature, \"foo\")\n",
    "\n",
    "    def _load_internal(self, instrument, start_index, end_index, *args):\n",
    "        series = self.feature.load(instrument, start_index, end_index, *args)\n",
    "        return np.abs(series) + np.log(series)\n",
    "    \n",
    "Operators.register([Abspluslog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.data.dataset.loader import QlibDataLoader\n",
    "\n",
    "qdl = QlibDataLoader(config=[('Abspluslog($chgPct)', '$chgPct'), ('ChgPctAbsPlusLogChgPct', 'ChgPct')])\n",
    "data = qdl.load(instruments=['000001.XSHE'], start_time='20200101', end_time='20201231', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we verify the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.ChgPct.abs().add(np.log(data.ChgPct)) == data.ChgPctAbsPlusLogChgPct).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qlib Rolling model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key point of rolling model training is that with the rolling window moves, the same data might be regenerated many times. For example, in the first rolling window, ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77040562760d700641a6b8d6adcf57b534b64ffdfbc7d9146d28184ff1d0c1ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
