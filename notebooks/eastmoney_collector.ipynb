{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eastmoney Collector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Emotion Collector for Guba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:09:27.396341Z",
     "iopub.status.busy": "2022-08-12T01:09:27.396206Z",
     "iopub.status.idle": "2022-08-12T01:09:28.164438Z",
     "shell.execute_reply": "2022-08-12T01:09:28.164149Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import random\n",
    "import hashlib\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import akshare as ak\n",
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "from diskcache import Cache\n",
    "from functools import wraps\n",
    "from dask.multiprocessing import get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:09:28.166128Z",
     "iopub.status.busy": "2022-08-12T01:09:28.166070Z",
     "iopub.status.idle": "2022-08-12T01:09:28.176146Z",
     "shell.execute_reply": "2022-08-12T01:09:28.175847Z"
    }
   },
   "outputs": [],
   "source": [
    "def cache_wrapper(directory: str = '../data/cache/', expire: int = 3600):\n",
    "    cache = Cache(directory=directory)\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            key = func.__name__ + ':' + hashlib.md5((func.__name__ + str(args) + str(kwargs)).encode('utf-8')).hexdigest()\n",
    "            result = cache.get(key=key)\n",
    "            if result is not None:\n",
    "                return result\n",
    "            result = func(*args, **kwargs)\n",
    "            cache.set(key=key, value=result, expire=expire)\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def wrap_code(code: str, formatstr: str = '{market}.{code}'):\n",
    "    if not code.isdigit():\n",
    "        raise ValueError('It seems your code has already been wrapped')\n",
    "    sh_code_pat = '6\\d{5}|9\\d{5}'\n",
    "    sz_code_pat = '0\\d{5}|2\\d{5}|3\\d{5}'\n",
    "    bj_code_pat = '8\\d{5}|4\\d{5}'\n",
    "    if re.match(sh_code_pat, code):\n",
    "        return formatstr.format(code=code, market='sh')\n",
    "    if re.match(sz_code_pat, code):\n",
    "        return formatstr.format(code=code, market='sz')\n",
    "    if re.match(bj_code_pat, code):\n",
    "        return formatstr.format(code=code, market='bj')\n",
    "    \n",
    "@cache_wrapper(expire=30 * 24 * 3600)\n",
    "def get_proxy(page_size: int = 20):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\"\n",
    "    }\n",
    "    url_list = [f'https://free.kuaidaili.com/free/inha/{i}/' for i in range(1, page_size + 1)]\n",
    "    proxies = []\n",
    "    for url in url_list:\n",
    "        data = pd.read_html(url)[0][['IP', 'PORT', '类型']].drop_duplicates()\n",
    "        print(f'[+] {url} Get Success!')\n",
    "        data['类型'] = data['类型'].str.lower()\n",
    "        proxy = (data['类型'] + '://' + data['IP'] + ':' + data['PORT'].astype('str')).to_list()\n",
    "        proxies += list(map(lambda x: {x.split('://')[0]: x}, proxy))\n",
    "        time.sleep(0.8)\n",
    "    available_proxies = []\n",
    "    \n",
    "    for proxy in proxies:\n",
    "        try:\n",
    "            res = requests.get('https://www.baidu.com', \n",
    "                headers=headers, proxies=proxy, timeout=1)\n",
    "            res.raise_for_status()\n",
    "            available_proxies.append(proxy)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    \n",
    "    print(f'[=] Get {len(proxies)} proxies, while {len(available_proxies)} are available. '\n",
    "        f'Current available rate is {len(available_proxies) / len(proxies) * 100:.2f}%')\n",
    "    return proxies\n",
    "\n",
    "def proxy_request(\n",
    "    url: str, \n",
    "    proxies: 'dict | list', \n",
    "    retry: int = None, \n",
    "    timeout: int = 1,\n",
    "    delay: int = 0,\n",
    "    verbose: bool = True,\n",
    "    **kwargs\n",
    "):\n",
    "    if isinstance(proxies, dict):\n",
    "        proxies = [proxies]\n",
    "    retry = retry or len(proxies)\n",
    "    random.shuffle(proxies) \n",
    "    for try_times, proxy in enumerate(proxies):\n",
    "        if try_times + 1 <= retry:\n",
    "            try:\n",
    "                response = requests.get(url, proxies=proxy, timeout=timeout, **kwargs)\n",
    "                response.raise_for_status()\n",
    "                if verbose:\n",
    "                    print(f'[+] {url}, try {try_times + 1}/{retry}')\n",
    "                return response\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f'[-] [{e}] {url}, try {try_times + 1}/{retry}')\n",
    "                time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:09:28.177557Z",
     "iopub.status.busy": "2022-08-12T01:09:28.177481Z",
     "iopub.status.idle": "2022-08-12T01:09:28.179182Z",
     "shell.execute_reply": "2022-08-12T01:09:28.178975Z"
    }
   },
   "outputs": [],
   "source": [
    "today = datetime.datetime.today().date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the utility function `get_proxy` to get some proxies for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:09:28.180416Z",
     "iopub.status.busy": "2022-08-12T01:09:28.180343Z",
     "iopub.status.idle": "2022-08-12T01:09:28.181947Z",
     "shell.execute_reply": "2022-08-12T01:09:28.181753Z"
    }
   },
   "outputs": [],
   "source": [
    "proxies = get_proxy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl for the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is dedicated to crawl the up or down possibility provided by investers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:09:28.183335Z",
     "iopub.status.busy": "2022-08-12T01:09:28.183263Z",
     "iopub.status.idle": "2022-08-12T01:09:28.185550Z",
     "shell.execute_reply": "2022-08-12T01:09:28.185369Z"
    }
   },
   "outputs": [],
   "source": [
    "def crawl_stock(code: str):\n",
    "    today = datetime.datetime.today().date()\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.6 Safari/605.1.15\",\n",
    "        \"Referer\": \"http://guba.eastmoney.com/\",\n",
    "        \"Host\": \"gubacdn.dfcfw.com\"\n",
    "    }\n",
    "    code = wrap_code(code, '{market}{code}')\n",
    "    url = f\"http://gubacdn.dfcfw.com/LookUpAndDown/{code}.js\"\n",
    "    res = requests.get(url, headers=headers)\n",
    "    res.raise_for_status()\n",
    "    res = eval(res.text.strip('var LookUpAndDown=').replace('null', f'\"{today}\"'))\n",
    "    data = pd.Series(res['Data'])\n",
    "    data['code'] = code\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:09:28.186787Z",
     "iopub.status.busy": "2022-08-12T01:09:28.186728Z",
     "iopub.status.idle": "2022-08-12T01:10:07.674568Z",
     "shell.execute_reply": "2022-08-12T01:10:07.674267Z"
    }
   },
   "outputs": [],
   "source": [
    "codes = ak.stock_zh_a_spot_em()['代码'].to_list()\n",
    "dsk = dict(zip(['result:' + code for code in codes], [(crawl_stock, code) for code in codes]))\n",
    "datas = get(dsk, list(dsk.keys()))\n",
    "data = pd.concat(datas, axis=1).T\n",
    "data.Date = pd.to_datetime(data.Date)\n",
    "data = data.set_index('code')\n",
    "data = data.astype({\"TapeZ\": \"float32\", \"TapeD\": \"float32\", \"TapeType\": \"uint8\", \"Date\": \"datetime64[ns]\"})\n",
    "data.to_parquet(f'../data/derivative-indicators/guba-votes/{today}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl the Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:10:07.676303Z",
     "iopub.status.busy": "2022-08-12T01:10:07.676216Z",
     "iopub.status.idle": "2022-08-12T01:10:07.680092Z",
     "shell.execute_reply": "2022-08-12T01:10:07.679877Z"
    }
   },
   "outputs": [],
   "source": [
    "def overview(code: str, page: int, try_times: int = 100):\n",
    "    tries = 0\n",
    "    while tries <= try_times:\n",
    "        page = str(page)\n",
    "        url = f\"http://guba.eastmoney.com/list,{code},f_{page}.html\"\n",
    "        html = etree.HTML(proxy_request(url, proxies=proxies, verbose=False).text)\n",
    "        read = html.xpath('//*[@id=\"articlelistnew\"]/div[not(@class=\"dheader\")]/span[1]/text()')\n",
    "        comments = html.xpath('//*[@id=\"articlelistnew\"]/div[not(@class=\"dheader\")]/span[2]/text()')\n",
    "        title = html.xpath('//*[@id=\"articlelistnew\"]/div[not(@class=\"dheader\")]/span[3]/a/text()')\n",
    "        href = html.xpath('//*[@id=\"articlelistnew\"]/div[not(@class=\"dheader\")]/span[3]/a/@href')\n",
    "        author = html.xpath('//*[@id=\"articlelistnew\"]/div[not(@class=\"dheader\")]/span[4]/a/font/text()')\n",
    "        time = html.xpath('//*[@id=\"articlelistnew\"]/div[not(@class=\"dheader\")]/span[5]/text()')\n",
    "        # we might still got unaligned data because the anti-crawl system\n",
    "        try:\n",
    "            data = pd.DataFrame({\"read\": read, \"comments\": comments, \"title\": title, \"href\": href, \"author\": author, \"datetime\": time})\n",
    "            return data\n",
    "        except:\n",
    "            tries += 1\n",
    "            print(f\"try time {tries} for page {page} aligned failed, that's probably because the proxy ip is banned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T01:10:07.681397Z",
     "iopub.status.busy": "2022-08-12T01:10:07.681321Z",
     "iopub.status.idle": "2022-08-12T01:12:44.936284Z",
     "shell.execute_reply": "2022-08-12T01:12:44.935788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try time 1 aligned failed, that's probably because the proxy ip is banned.\n",
      "try time 1 aligned failed, that's probably because the proxy ip is banned.\n",
      "try time 1 aligned failed, that's probably because the proxy ip is banned.\n",
      "try time 1 aligned failed, that's probably because the proxy ip is banned.\n",
      "try time 1 aligned failed, that's probably because the proxy ip is banned.\n",
      "try time 1 aligned failed, that's probably because the proxy ip is banned.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "end_page = 500\n",
    "dsk = dict(zip(\n",
    "    [f'page{i}' for i in range(1, end_page + 1)],\n",
    "    [(overview, 'zssh000001', i) for i in range(1, end_page + 1)],\n",
    "))\n",
    "results = get(dsk, list(dsk.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today()\n",
    "year = today.year\n",
    "month = today.month\n",
    "for res in results:\n",
    "    res['datetime'] = res['datetime'].map(lambda x: (str(year) if int(x[:2]) <= month else str(year - 1)) + '-' + x)\n",
    "    res['datetime'] = pd.to_datetime(res['datetime'])\n",
    "    if (res['datetime'] < str(year)).any():\n",
    "        year -= 1\n",
    "result = pd.concat(results, axis=0)\n",
    "result = result.astype({\"read\": \"uint16\", \"comments\": \"uint16\"})\n",
    "result.to_parquet(f'../data/derivative-indicators/guba-comments/{today.date}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Financial Report Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "data = ak.stock_balance_sheet_by_report_em(symbol='SH600519')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACCEPT_DEPOSIT_INTERBANK', 'ACCOUNTS_PAYABLE', 'ACCOUNTS_RECE',\n",
       "       'ACCRUED_EXPENSE', 'ADVANCE_RECEIVABLES', 'AGENT_TRADE_SECURITY',\n",
       "       'AGENT_UNDERWRITE_SECURITY', 'AMORTIZE_COST_FINASSET',\n",
       "       'AMORTIZE_COST_FINLIAB', 'AMORTIZE_COST_NCFINASSET',\n",
       "       ...\n",
       "       'TOTAL_OTHER_RECE_YOY', 'TOTAL_PARENT_EQUITY_YOY',\n",
       "       'TRADE_FINASSET_NOTFVTPL_YOY', 'TRADE_FINASSET_YOY',\n",
       "       'TRADE_FINLIAB_NOTFVTPL_YOY', 'TRADE_FINLIAB_YOY',\n",
       "       'TREASURY_SHARES_YOY', 'UNASSIGN_RPOFIT_YOY',\n",
       "       'UNCONFIRM_INVEST_LOSS_YOY', 'USERIGHT_ASSET_YOY'],\n",
       "      dtype='object', length=304)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[data.astype('f8', errors='ignore').dtypes != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2022中报\n",
       "1     2022一季报\n",
       "2      2021年报\n",
       "3     2021三季报\n",
       "4      2021中报\n",
       "       ...   \n",
       "82     2001年报\n",
       "83     2001中报\n",
       "84     2000年报\n",
       "85     1999年报\n",
       "86     1998年报\n",
       "Name: REPORT_DATE_NAME, Length: 87, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.REPORT_DATE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "be461149623e13b126d9ab65bc78e9e52a75e1177f71df321c71dd4fbcccebcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
