{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Target Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 4\n",
    "forward = pd.read_parquet('../input/kline-daily/market_daily.parquet')\n",
    "forward = forward.adjclose.groupby(level=1).shift(-1 - period) / forward.adjopen.groupby(level=1).shift(-1) - 1\n",
    "forward = forward.dropna().unstack()\n",
    "forward = forward.mask(forward <= 0., 0).mask(forward > 0.0, 1)\n",
    "forward.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = '../input/features/'\n",
    "features = list(filter(lambda x: x.endswith('.parquet'), os.listdir('../input/features/')))\n",
    "\n",
    "datas = []\n",
    "for feat in features:\n",
    "    data = pd.read_parquet(features_dir + feat)\n",
    "    data_med = data.median(axis=1)\n",
    "    mad = data.subtract(data_med, axis=0).abs().median(axis=1)\n",
    "\n",
    "    data = data.clip(data_med - 5 * mad, data_med + 5 * mad, axis=0)\n",
    "    data = data.subtract(data.mean(axis=1), axis=0).divide(data.std(axis=1), axis=0)\n",
    "    data = data.fillna(0, axis=0)\n",
    "    datas.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datas + [forward]\n",
    "train_dataset = pd.concat(train_dataset, axis=0, keys=[feat[:-8] for feat in features] + ['target'])\n",
    "train_dataset = train_dataset.swaplevel().sort_index()\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward.loc[\"2010-01-11\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Constructing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function provides a method for training a model on a given day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_for_one_day(date: str, forward_period: int, training_period: int):\n",
    "    i = train_dataset.index.levels[0].get_loc(date)\n",
    "    training_end = train_dataset.index.levels[0][i - forward_period - 1]\n",
    "    training_start = train_dataset.index.levels[0][i - forward_period - training_period - 1]\n",
    "    csdata = train_dataset.loc[training_start:training_end].unstack().stack(level=0).dropna()\n",
    "    if csdata.columns.size > 1:\n",
    "        pca = PCA()\n",
    "        train_x_pca = pd.DataFrame(pca.fit_transform(csdata.loc[:, csdata.columns != 'target']), index=csdata.index)\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(train_x_pca, csdata['target'])\n",
    "        return model, csdata.columns[csdata.columns != 'target']\n",
    "    return [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_period = period\n",
    "training_period = period\n",
    "dates = train_dataset.index.levels[0][forward_period + training_period + 1:]\n",
    "models = []\n",
    "for date in tqdm(dates):\n",
    "    models.append(fit_for_one_day(date, forward_period, training_period))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing a model time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "features = []\n",
    "forward_index_str = forward.index.intersection(total_feature.index.levels[0]).strftime('%Y%m%d')\n",
    "\n",
    "for date in tqdm(forward_index_str):\n",
    "    model, feat = fit_for_one_day(date)\n",
    "    models.append(model)\n",
    "    features.append(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model on the last relocate date to predict the next period's forward return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuation = pd.Series(index=forward_index_str[1:], dtype='float32')\n",
    "predictions = pd.DataFrame(index=forward_index_str, columns=total_feature.columns)\n",
    "for i in range(len(forward_index_str) - 1):\n",
    "    date = forward_index_str[i + 1]\n",
    "    if features[i].isin(total_feature.loc[date].index).all():\n",
    "        data = pd.concat([total_feature.loc[date].T.loc[:, features[i]], forward.loc[date]], axis=1).dropna()\n",
    "        model = models[i]\n",
    "        y_pred = pd.Series(model.predict(data.loc[:, features[i]].values), index=data.index)\n",
    "        valuation.loc[date] = accuracy_score(data.iloc[:, -1].values, y_pred.values)\n",
    "        predictions.loc[date] = y_pred\n",
    "    else:\n",
    "        valuation.loc[date] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization and valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = valuation.plot.bar(figsize=(12, 6))\n",
    "ax.set_xticks(ax.get_xticks()[::50])\n",
    "_ = ax.set_xticklabels(valuation.index[::50], rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(valuation.mean(), valuation.std(), valuation.mean() / valuation.std(), \n",
    "    valuation[valuation > valuation.mean()].size / valuation.size, ttest_1samp(valuation.dropna(), 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be461149623e13b126d9ab65bc78e9e52a75e1177f71df321c71dd4fbcccebcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
